---
title: "3 Topic modeling"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Topic modeling with latent Dirichlet allocation (LDA).

```{r setup, message=FALSE, warning=FALSE}
library(rfintext)
library(quanteda)
library(tidytext)
library(topicmodels)  # LDA
library(topicdoc)  # Coherence score
library(dplyr)  # Tidyverse friends
library(tidyr)  # Tidyverse friends
library(forcats)  # Tidyverse friends
library(purrr)  # Tidyverse friends
library(tidyr)  # Tidyverse friends
library(ggplot2)  # Tidyverse friends
library(cowplot)  # Multiple plots made easy
library(future)  # Parallel processing back-end
library(furrr)  # Parallel processing front-end with future_ functions
plan(multisession, workers = availableCores(logical = FALSE) - 1)  # Utilize multiple cores on time consuming tasks.
```

```{r, include=FALSE}
quanteda_options(print_dfm_max_ndoc = 20, print_dfm_max_nfeat = 20)
```

You know already how to pre process and convert to document term matrix: 

```{r, message=FALSE, R.options = list(width = 10000)}
dtm <- aspol |>
  preprocess_corpus(kunta) |>
  count(kunta, LEMMA) |>
  cast_dfm(kunta, LEMMA, n)  # n is default name from dplyr::count()
dtm
```

Let's get straight to business. Unsupervised classification with LDA:

LDA needs one parameter `k`. Finding optimal values by evaluating coherence score.

> Note! Following will take some time even with multiple cores. For me it took 
around half an hour on laptop with 14 cores. Adjust number of K values 
accordingly. Here we test the whole scale for number of topics ranging from two 
to number of documents.


```{r, warning=FALSE, message=FALSE}
ptm <- proc.time()
lda_models <- tibble(K = 2:68) |>
  mutate(
    # LDA models
    topic_model = future_map(  
      # K, ~LDA(convert(dtm, to = "tm"), k = ., control = list(seed = 1234)),  # Seed in parallel processing (problem?)
      K, ~LDA(convert(dtm, to = "tm"), k = .),  # LDA expects dtm in tm format (or does it?)
      .options = furrr_options(seed = TRUE)
    ),
    # Model coherence
    mean_coherence = future_map_dbl(
      topic_model, \(x) mean(topic_coherence(x, dtm))
    )
  )
proc.time() - ptm
lda_models
```


```{r}
p <- lda_models |>
  ggplot(aes(x = K, y = mean_coherence)) +
  geom_line() +
  labs(subtitle = "LDA model coherence with different topic numbers", 
       x = "k (number of topics)", y = "Mean coherence")
p
```

Visually selecting potentially best k values

```{r}
# optimal_k <- c(5, 9, 11, 15, 20)
optimal_k <- c(6, 10, 16)
```


```{r}
p +
  geom_vline(xintercept = optimal_k, linetype='dashed', color=c('red')) +
  lapply(optimal_k, function(x) {geom_text(aes(x=x+1, label=x, y=-5), colour="red", angle=90)}) +
  labs(subtitle = "Optimal k values",
       x = "k (number of topics)", y = "Mean coherence")
```

> NOTE! Coherence scores can change even for smallest adjustments to pre processing 
pipeline. Make your mind on those first and stick to it.

Highest coherence values: `r optimal_k`

```{r}
selected_models <- lda_models |>
  filter(K %in% optimal_k)
selected_models
```

Extract beta and theta matrices with probabilities for terms per topic and 
documents per topic repectively.

> Note! `r tidytext::tidy()` uses term gamma-matrix while in the research field 
term theta-matrix is used to describe probability distribution of topics per document. 
Here we rename gamma as theta. Do not get confused if at some point you come around 
with gamma instead of theta.


```{r}
selected_models <- selected_models |>
  mutate(
    # Beta matrix
    beta = map(
      topic_model, \(x) tidy(x, matrix = "beta")
    ),
    # Theta matrix (gamma)
    theta = map(
      topic_model, \(x) {
        tidy(x, matrix = "gamma") |> 
          rename(theta = gamma)
      }
    )
  )
selected_models
```

This is all good. Next parts look ugly but hopefully they work. We take a look 
at correlation between topics from different models to see if different models 
catch up same things. 

```{r}
topic_congruence <- list()
for (i in selected_models$K) {
  topic_congruence[[paste0("model-", i)]] <- selected_models |>
  select(K, beta) |>
  unnest(beta) |>
  filter(K==i) |>
  pivot_wider(values_from = beta, names_from = topic) |>
  select(-term, -K)
}
topic_congruence
```

Compare all possible pairs of models: 

```{r}
# combn(selected_models$K, 2)
```

```{r}
topic_congruence2 <- list()
for (idx_col in 1:ncol(combn(selected_models$K, 2))) {
  idx <- combn(selected_models$K, 2)[, idx_col]
  correlation <- cor(topic_congruence[[paste0("model-", idx[1])]], topic_congruence[[paste0("model-", idx[2])]])
  topic_congruence2[[paste0("model-", idx[1], "-", idx[2])]] <- correlation |> 
    as_tibble(rownames = "topic1") |>
    pivot_longer(!topic1, names_to = "topic2", values_to = "r")
}
topic_congruence2 <- bind_rows(topic_congruence2, .id = "model-K")
topic_congruence2
```

```{r, fig.width=14, fig.height=7}
topic_congruence2 |>
  mutate(`model-K`= factor(`model-K`),
         topic1 = factor(as.integer(topic1)),
         topic2 = factor(as.integer(topic2)),
         r = round(r, 2)) |>
  ggplot(aes(x = topic1, y = topic2, fill = r, label = r)) +
  geom_tile(show.legend = FALSE) +
  geom_text() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(title = "Topic congruence between different models") +
  scale_fill_viridis_c(option = "A") +
  facet_wrap(~`model-K`, scales = "free", ncol = 3)
```

```{r, fig.width=14, fig.height=7}
selected_models |>
  select(K, theta) |>
  unnest(theta) |>
  mutate(topic = factor(as.integer(topic))) |>
  summarise(mean_theta = mean(theta),
            total_theta = sum(theta), .by = c(K, topic)) |>
  ggplot() +
  geom_col(aes(x = topic, y = total_theta)) +
  labs(title = "Topic prevalence") +
  facet_wrap(~K, scales = "free", ncol = 3)
```

Theta value is probability of document belonging to or comprising of certain 
topics. Histogram over topic probabilities shows how common it is for specific 
topic to comprise the whole document (height of a column at theta 1.0).

```{r, fig.width=14, fig.height=21}
selected_models |>
  select(K, theta) |>
  unnest(theta) |>
  ggplot(aes(x = theta)) +
  geom_histogram(binwidth = 0.1) +
  labs(title = "Topic histograms") +
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(K~topic, scales = "free_y")
```




```{r, fig.height=7, fig.width=14}
selected_models |>
  select(K, theta) |>
  unnest(theta) |>
  mutate(topic = factor(as.integer(topic))) |>
  ggplot(aes(x = topic, y = theta, group = topic)) +
  geom_boxplot(show.legend = FALSE) +
  labs(title = "Topic distributions per document") +
  facet_wrap(~K, scales = "free", ncol = 3)
```

```{r, fig.width=14, fig.height=21}
selected_models |>
  select(K, beta) |>
  unnest(beta) |>
  slice_max(beta, n = 25, by = c(K, topic)) |>
  group_by(K) |>
  add_count(term) |>
  ungroup() |>
  mutate(is_unique = n == 1,
         K = factor(K),
         topic = factor(topic),
         term = reorder_within(term, beta, topic)) |>
  ggplot(aes(x = beta, y = term, fill = K)) +
  geom_col(show.legend = FALSE) +
  labs(title = "25 terms with highest probability per topic") +
  scale_y_reordered() +
  facet_wrap(K ~ topic, scales = "free", ncol = 7)
```


```{r, fig.height=21, fig.width=14}
# for (i in unique(beta_matrix$model)) {
#   print(
#     beta_matrix |>
#       filter(model == i) |>
#       group_by(topic) |>
#       slice_max(beta, n = 25) |>
#       mutate(topic = as.factor(paste0("Topic_", topic))) |>
#       ggplot(aes(x = beta, y = reorder(term, beta), fill = topic)) +
#       geom_col(show.legend = FALSE) +
#       scale_fill_viridis_d(option = "A") +
#       facet_wrap(~topic, scales = "free") +
#       labs(title = "Top 25 terms by topic", subtitle = paste0("Model_", i), x = "Probability", y = "Term")
#   )
# }
```

```{r, fig.height=21, fig.width=14}
# for (i in unique(beta_matrix$model)) {
#   print(
#     beta_matrix |>
#       filter(model == i) |>
#       group_by(topic) |>
#       slice_max(beta, n = 25) |>
#       mutate(topic = as.factor(paste0("Topic_", topic))) |>
#       ungroup() |>
#       add_count(term, name = "in_topics") |>
#       filter(in_topics == 1) |>
#       ggplot(aes(x = beta, y = reorder(term, beta), fill = topic)) +
#       geom_col(show.legend = FALSE) +
#       scale_fill_viridis_d(option = "A") +
#       facet_wrap(~topic, scales = "free", ncol = 2) +
#       labs(title = "Unique terms out of top 25 terms by topic", subtitle = paste0("Model_", i), x = "Probability", y = "Term")
#   )
# }
```

```{r, R.options=list(width = 10000)}
# doc_topics <- lapply(lda_models, function(x) {
#   x |>
#     tidytext::tidy(matrix = "gamma") |>
#     tidytext::cast_dfm(document, topic, gamma)
# })
# doc_topics
```



```{r}
# join_y <- function(df) {
#   df |>
#     left_join(taantuvat, by = join_by("doc_id" == "kunta")) |>
#     filter(!is.na(luokka))
# }
```

```{r}
# summarise_topics <- function(df, ...) {
#   df |>
#     mutate(topic = factor(as.integer(topic))) |>
#     summarise(...)
# }
```


```{r}
# plot_topic_mean_prop <- function(df, ...) {
#   df |>
#     ggplot() +
#     geom_point(aes(...))
# }
```

```{r}
# lapply(doc_topics, function(x) { 
#   x |>
#     gather_topic_prob() |>
#     join_y() |>
#     summarise_topics(sum_prop = sum(prop), .by = c(luokka, topic)) |>
#     plot_topic_mean_prop(x = topic, y = sum_prop, colour = luokka)
# }
# )
```

```{r}
# lapply(doc_topics, function(x) { 
#   x |>
#     gather_topic_prob() |>
#     join_y() |>
#     summarise_topics(mean_prop = mean(prop), .by = c(luokka, topic)) |>
#     plot_topic_mean_prop(x = topic, y = mean_prop, colour = luokka)
# }
# )
```


```{r}
# taantuvat |>
#   filter(kunta %in% unique(aspol$kunta)) |>
#   mutate(luokka = if_else(suht_muutos_2010_2022 > 0, "Kasvava", "Taantuva")) |>
#   count(luokka, sort = TRUE)
```

```{r}
# purrr::imap(doc_topics, function(x, name) { 
#   x |>
#     gather_topic_prob() |>
#     join_y() |>
#     select(doc_id, topic, prop, suht_muutos_2010_2022, luokka) |>
#     tidyr::pivot_wider(names_from = topic, values_from = prop) |>
#     rename_with(~ paste0("topic_", .x, recycle0 = TRUE), matches("^[0-9]+$")) |>
#     write.csv(paste0("topic_", name, ".csv"))
# })
```


```{r}
# dat <- doc_topics$k_5 |> 
#   gather_topic_prob() |>
#   join_y() |>
#   mutate(luokka = if_else(suht_muutos_2010_2022 > 0, "Kasvava", "Taantuva"),
#          topic = factor(as.integer(topic))) |>
#   select(topic, prop, luokka)
# dat
```

```{r}
# for (i in seq_along(unique(dat$topic))) {
#   cat("Topic ", i)
#   print(
#     dat |> filter(topic == i) |>
#     ggplot() +
#     geom_boxplot(aes(x = luokka, y = prop)) +
#       labs(title = paste0("Topic ", i))
#     )
#   print(
#     dat |>
#       filter(topic == i) |>
#       kruskal.test(luokka ~ prop, data = _)
#   )
# } 
```


```{r}
# doc_topics$k_5 |>
#   gather_topic_prob() |>
#   join_y() |>
#   mutate(luokka = if_else(suht_muutos_2010_2022 > 0, "Kasvava", "Taantuva"),
#          topic = factor(as.integer(topic))) |>
#   summarise(topic_sum = sum(prop), 
#             topic_mean = mean(prop),
#             .by = c(luokka, topic)) |>
#   kruskal.test(topic_sum ~ luokka)
```

```{r}
# lapply(doc_topics, function(x) { 
#   x |>
#     gather_topic_prob() |>
#     join_y() |>
#     mutate(luokka = if_else(suht_muutos_2010_2022 > 0, "Kasvava", "Taantuva"),
#            topic = factor(as.integer(topic))) |>
#     summarise(mean_prop = mean(prop), .by = c(luokka, topic)) |>
#     tidyr::pivot_wider(names_from = luokka, values_from = mean_prop) |>
#     mutate(diff = Kasvava-Taantuva) |>
#     ggplot() +
#     geom_point(aes(x = topic, y = diff)) +
#     ylim(-0.4, 0.4) +
#     geom_hline(yintercept = 0)
# })
```


```{r}
# lapply(doc_topics, function(x) { 
#   x |>
#     gather_topic_prob() |>
#     join_y() |>
#     mutate(luokka = if_else(suht_muutos_2010_2022 > 0, "Kasvava", "Taantuva"),
#            topic = factor(as.integer(topic))) |>
#     summarise(topic_sum = sum(prop), 
#               topic_mean = mean(prop),
#               .by = c(luokka, topic)) |>
#     ggplot() +
#     geom_tile(aes(x = topic, y = luokka, fill = topic_sum)) +
#     scale_fill_viridis_c(option = "A")
# }
# )
```

```{r}
# lapply(doc_topics, function(x) { 
#   x |>
#     gather_topic_prob() |>
#     join_y() |>
#     mutate(luokka = if_else(suht_muutos_2010_2022 > 0, "Kasvava", "Taantuva"),
#            topic = factor(as.integer(topic))) |>
#     summarise(topic_sum = sum(prop), 
#               topic_mean = mean(prop),
#               .by = c(luokka, topic)) |>
#     ggplot() +
#     geom_tile(aes(x = topic, y = luokka, fill = topic_mean)) +
#     scale_fill_viridis_c(option = "A")
# }
# )
```

```{r}
# lapply(doc_topics, function(x) { 
#   x |>
#     gather_topic_prob() |>
#     join_y() |>
#     mutate(luokka = if_else(suht_muutos_2010_2022 > 0, "Kasvava", "Taantuva"),
#            topic = factor(as.integer(topic))) |>
#     summarise(mean_prop = mean(prop), .by = c(luokka, topic)) |>
#     tidyr::pivot_wider(names_from = luokka, values_from = mean_prop) |>
#     mutate(diff = Kasvava-Taantuva) |>
#     tidyr::pivot_longer(Kasvava:Taantuva, names_to = "luokka", values_to = "prop") |>
#     ggplot() +
#     geom_tile(aes(x = topic, y = luokka, fill = diff)) +
#     scale_fill_distiller(palette = "Spectral")
# })
```

```{r}
# titles <- aspol |> 
#   group_by(kunta) |> 
#   slice_head(n=10) |> 
#   summarise(title = paste(FORM, collapse = " ")) |>
#   inner_join(taantuvat)
# titles
```

```{r}
# titles_per_topics <- lapply(doc_topics, function(x) {
#   gather_topic_prob(x) |>
#     slice_max(order_by = prop, n = 1, by = doc_id) |>
#     left_join(titles, by = join_by("doc_id" == "kunta"))
#   })
# titles_per_topics
```

```{r, rows.print=16, }
# titles_per_topics$k_5 |>
#   filter(topic==3) |>
#   select(doc_id, title)
```


```{r}
# doc_topics$k_5 |> convert(to = "data.frame") |>
#   tidyr::pivot_longer(!doc_id, names_to = "topic", values_to = "prop") |>
#   left_join(taantuvat, by = join_by("doc_id" == "kunta")) |>
#   filter(!is.na(luokka)) |>
#   group_by(luokka, topic) |>
#   summarise(mean_prop = mean(prop)) |>
#   ggplot() +
#   geom_point(aes(x = topic, y = mean_prop, colour = luokka))
```


```{r}
# doc_topics$k_5 |> convert(to = "data.frame") |>
#   tidyr::pivot_longer(!doc_id, names_to = "topic", values_to = "prop") |>
#   ggplot() +
#   geom_col(aes(x = prop, y = topic))
```

